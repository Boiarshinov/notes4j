---
title: "Apache Kafka"
tags:
  - tool
  - event_log
  - queue
draft: True
---

# Apache Kafka

**Apache Kafka** - это лог событий.
Kafka поставляется в виде кластера.

Иногда Kafka называют очередью сообщений, но это не совсем верно, потому что Kafka в отличие от очереди не позволяет выкидывать из нее объекты.

Kafka может использоваться для:
- интеграции различных систем
- распределенного лога
- потоковой обработки

В Kafka записываются события (**Event**).
Событие - это уведомление о состоянии какой-либо сущности.
Например, результат измерения температуры котла в определенный момент времени.

События записываются в топики.
**Топик** - это бесконечный свиток, в который записываются события, объединенные по какому-то признаку. 
Все новые события дозаписываются в конец топика.
Топики персистентны и по умолчанию из них ничего не удаляется, но при желании можно выставить ограничение на размер топика или на срок жизни записей.
С точки зрения внутреннего устройства Kafka топик - это обычный файл в файловой системе.

Внутри Kafka событие представляется в виде пары ключ - значение.
Ключ необязательно должен быть уникальным.
Скорее ключ - это тип события.

Данные в Kafka хранятся в виде массива байт.
Поэтому чаще всего данные сериализуются в массив байт с помощью какого-либо бинарного формата. 
Например: Avro, Protobuf или JSON в кодировке UTF-8.


## Партиционирование топиков

Для того чтобы файлы, в которых хранятся топики, не разрастались до гигантских размеров, их дробят на партиции.
Каждая партиция хранится на своей ноде кластера Kafka.

События распределяются по партициям на основании значения ключа.
От ключа высчитывается хэш и берется остаток от деления на количество партиций.
Полученное число - номер партиции, в которую попадет запись.
Если ключ не задан, то партиции распределяются равномерно по алгоритму [round robin](../algorithms/round_robin.md)


## Брокеры

Брокер - это конкретный инстанс Kafka, входящий в кластер.
Это JVM процесс, запущенный на сервере или в контейнере.
Каждый брокер отвечает за обработку одной или нескольких партиций.
Также брокеры занимаются репликацией данных между друг другом


## Репликация

Для того чтобы не потерять данные при выходе из строя одного из брокеров, партиции реплицируются между различными брокерами.
Главная партиция называется лидер-репликой, а запасные - follower-репликами. 
Чтение и запись всегда происходит через лидер-реплику. 
Лидер-реплика сама реплицирует новые данные фолловерам.

При падении брокера, на котором находилась лидер-реплика, лидером становится одна из follower-реплик.


## Продюсеры и Консьюмеры

Продюсеры пишут в Kafka, консьюмеры - читают из нее.
Продюсеры и консьюмеры представлены в виде клиентских библиотек для Java.

<mark>Описать подробнее</mark>

```java
KafkaProducer
ProducerRecord

KafkaConsumer
ConsumerRecord
```

Топики могут читаться несколькими консьюмер группами. 
Каждая группа имеет свой оффсет.
В одну группу обычно входят инстансы одного приложения.
Каждый консьюмер в группе читает свои партиции.
Распределение партиций между консьюмерами осуществляется Kafka - самому настраивать ничего не нужно.
При изменении количества консьюмеров в группе (падение инстанса, поднятие нового пода), партиции автоматически перераспределяются.
Количество консьюмеров в группе не должно превышать количество партиций, иначе останутся консьюмеры, которые вообще ничего не читают.
Желательно, чтобы количество партиций было кратно количество консьюмеров в группе.


## Экосистема Kafka

В экосистему Kafka помимо Kafka брокеров и клиентских библиотек входят еще несколько продуктов:
- [Kafka Connect](kafka_connect.md) - инструмент для переливки данных между различными хранилищами и Kafka
- Schema Registry - база данных на основе Kafka, в которой хранятся схемы сообщений (`.proto`, `.avsc` или `.json-schema`). Разворачивается в виде распределенного приложения с REST интерфейсом. Библиотеки продюсеров и консьюмеров имеют встроенных клиентов для обращения к Schema Registry. Особенно Schema Registry полезна, когда мы используем Kafka в качестве асинхронного публичного API, тогда пользователи API смогут узнать о формате сообщений из Schema Registry.
- Kafka Streams - Java API, позволяющий в функциональном стиле обрабатывать приходящие сообщения в консьюмере, обогащая их данными из других источников.
- ksqlDB - отдельное распределенное приложение, подключающееся к кластеру Kafka и предоставляющее REST интерфейс. Этот интерфейс может использоваться для стриминговой обработки данных с помощью SQL запросов (какая-то ведьминская магия).


---
## К изучению

- [X] [Краткий курс от Confluent](https://developer.confluent.io/learn-kafka/apache-kafka/events/)
- [ ] [Рекомендацию по именованию топиков](https://devshawn.com/blog/apache-kafka-topic-naming-conventions/)